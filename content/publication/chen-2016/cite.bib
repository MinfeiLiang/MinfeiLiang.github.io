@inproceedings{Chen2016,
 abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable endto-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
 author = {Tianqi Chen and Carlos Guestrin},
 city = {New York, NY, USA},
 doi = {10.1145/2939672.2939785},
 isbn = {9781450342322},
 journal = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 month = {8},
 pages = {785-794},
 publisher = {ACM},
 title = {XGBoost},
 url = {https://dl.acm.org/doi/10.1145/2939672.2939785},
 volume = {13-17-August-2016},
 year = {2016}
}
